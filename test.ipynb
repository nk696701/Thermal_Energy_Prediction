{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flirimageextractor\n",
    "from matplotlib import cm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocess():\n",
    "    def __init__(self):\n",
    "        self.model = flirimageextractor.FlirImageExtractor(palettes=[cm.jet, cm.bwr, cm.gist_ncar])\n",
    "        \n",
    "    def extract_thermal_image(self, img_path):\n",
    "        self.model.process_image(img_path)\n",
    "        return self.model.get_thermal_np()\n",
    "\n",
    "def create_cnn(width=140, height=140, depth=1, filters=(16, 32, 64), regress=False):\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "\n",
    "    inputs = tf.keras.Input(shape=inputShape)\n",
    "\t    # loop over the number of filters\n",
    "    for (i, f) in enumerate(filters):\n",
    "            # if this is the first CONV layer then set the input\n",
    "            # appropriately\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "            # CONV => RELU => BN => POOL\n",
    "        x = tf.keras.layers.Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(16)(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "        # apply another FC layer, this one to match the number of nodes\n",
    "        # coming out of the MLP\n",
    "    x = tf.keras.layers.Dense(4)(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        # check to see if the regression node should be added\n",
    "    if regress:\n",
    "        x = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "    # construct the CNN\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    # return the CNN\n",
    "    return model     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessiong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'dataset/230209_IR directory_2.8 V/'\n",
    "images_path = base_path+'images/'\n",
    "prep = preprocess()\n",
    "labels = []\n",
    "\n",
    "for file in os.listdir(images_path):\n",
    "    fmt = file.split('.')\n",
    "\n",
    "    if fmt[-1] == \"jpg\":\n",
    "        id = fmt[0]\n",
    "        labels.append(id.split('_')[-1])\n",
    "        img_path = images_path+file\n",
    "        thermal_img = prep.extract_thermal_image(img_path)\n",
    "        plt.imshow(thermal_img)\n",
    "        data_path = base_path +'thermal_data/' + id + '.npy'\n",
    "        np.save(data_path, thermal_img)\n",
    "\n",
    "labels.sort()      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'dataset/230209_IR directory_2.8 V/'\n",
    "idx = set(range(16))\n",
    "train_idx =  set(random.sample(idx, 10))\n",
    "test_idx = idx - train_idx\n",
    "Y_train = Y[list(train_idx)]\n",
    "Y_test = Y[list(test_idx)]\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for i in train_idx:\n",
    "    X_train.append(np.load(base_path + 'thermal_data/IR_' + labels[i]+'.npy'))\n",
    "\n",
    "for i in test_idx:\n",
    "    X_test.append(np.load(base_path + 'thermal_data/IR_' + labels[i]+'.npy'))\n",
    "\n",
    "X_train = np.array(X_train)/100\n",
    "X_test = np.array(X_test)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(width=144, height=144, depth=1, filters=(16, 32, 64)):\n",
    "    inputShape = (height, width, depth)\n",
    "    chanDim = -1\n",
    "\n",
    "    inputs = tf.keras.Input(shape=inputShape)\n",
    "\t    # loop over the number of filters\n",
    "    for (i, f) in enumerate(filters):\n",
    "        if i == 0:\n",
    "            x = inputs\n",
    "            # CONV => RELU => BN => POOL\n",
    "        x = tf.keras.layers.Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "        x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "        x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(128)(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(64)(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(16)(x)\n",
    "    x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=chanDim)(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(11)(x)\n",
    "    x = tf.keras.layers.Activation(\"softmax\")(x)\n",
    "    # construct the CNN\n",
    "    model = tf.keras.Model(inputs, x)\n",
    "    # return the CNN\n",
    "    return model  \n",
    "\n",
    "model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer='adam')\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1000, batch_size = 150, verbose=1, validation_split=0.2)\n",
    "\n",
    "test_results = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step - loss: 69.1116 - val_loss: nan\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 71.2913 - val_loss: nan\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 74.5047 - val_loss: nan\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 68.9283 - val_loss: nan\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 70.6451 - val_loss: nan\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 73.7369 - val_loss: nan\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 77.5239 - val_loss: nan\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 71.9024 - val_loss: nan\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 67.7643 - val_loss: nan\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 72.0187 - val_loss: nan\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 68.4499 - val_loss: nan\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 76.1212 - val_loss: nan\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 74.7195 - val_loss: nan\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 80.0835 - val_loss: nan\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 74.0735 - val_loss: nan\n",
      "1/1 [==============================] - 0s 98ms/step\n"
     ]
    }
   ],
   "source": [
    "model = create_cnn(140, 140, 1, regress=True)\n",
    "opt = tf.keras.optimizers.Adam(lr=1e-3, decay=1e-3 / 200)\n",
    "model.compile(loss=\"mean_absolute_percentage_error\", optimizer=opt)\n",
    "# train the model\n",
    "print(\"[INFO] training model...\")\n",
    "model.fit(x=X_train, y=Y_train, \n",
    "    validation_data=(X_test, Y_test),\n",
    "    epochs=1000, batch_size=150)\n",
    "\n",
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted : [nan nan nan nan nan nan]\n",
      "Actual : [31.25 37.5  43.75 50.   56.25 75.  ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted :\", preds.flatten())\n",
    "print(\"Actual :\", Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
